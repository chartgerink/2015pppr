install.packages('devtools')
update.packages(checkBuilt = T, ask = F, type = "binary")
update.chjh
update.chjh
update.chjh()
plot(dbeta(shape1 = 1, shape2 = 1))
?dbeta
dbeta(seq(0, 1, .001), shape1 = 1, shape2 = 1)
plot(dbeta(seq(0, 1, .001), shape1 = 1, shape2 = 1))
for(beta in seq(.99, .9, -.01))
lines(dbeta(seq(0, 1, .001), shape1 = 1, shape2 = beta))
plot(dbeta(seq(0, 1, .001), shape1 = 1, shape2 = 1))
for(beta in seq(.99, .9, -.01))
lines(x = dbeta(seq(0, 1, .001), shape1 = 1, shape2 = beta))
plot(x = dbeta(seq(0, 1, .001), shape1 = 1, shape2 = 1))
for(beta in seq(.99, .9, -.01))
lines(x = dbeta(seq(0, 1, .001), shape1 = 1, shape2 = beta))
beta
dbeta(seq(0, 1, .001), shape1 = 1, shape2 = beta)
rbeta(n = 10, shape1 = 1, shape2 = .9)
rbeta(n = 10, shape1 = 1, shape2 = .9)
rbeta(n = 10, shape1 = 1, shape2 = .9)
rbeta(n = 10, shape1 = 1, shape2 = .9)
dbeta(seq(0, 1, .001), shape1 = 1, shape2 = beta)
density(dbeta(seq(0, 1, .001), shape1 = 1, shape2 = beta))
density(dbeta(seq(0, 1, .001), shape1 = 1, shape2 = beta))?dbeta
?dbeta
plot(x = c(.2, .5, .8), y = c(.09, .34, .69), type = 'o')
lines(x = c(.2, .5, .8), y = c(.14, .60, .94), type = 'o', pch =3)
lines(x = c(.2, .5, .8), y = c(.24, .88, .999), type = 'o', pch = 2)
plot(x = c(.2, .5, .8), y = c(.09, .34, .69), type = 'o', ylim = c(0,1), xlim = c(0,1))
lines(x = c(.2, .5, .8), y = c(.14, .60, .94), type = 'o', pch =3)
lines(x = c(.2, .5, .8), y = c(.24, .88, .999), type = 'o', pch = 2)
.2*200
sprintf("Dit %s is het getal één %s", 1, 2)
sprintf("Dit %s is het getal één %s", 1, c(1,2))
sprintf("Dit %s is het getal één %s", c(1, 2))
sprintf("Dit %s is het getal één %s", 1:100, 1:100)
expand.grid(1:10, 1:10)
expand.grid(1:5, 1:5)
expand.grid(1:5, 1:5, 1:5)
t.03875=abs(qt(.03875/2,df=38))
t.04    =abs(qt(.04/2,   df=38))
t.04875=abs(qt(.04875/2,df=38))
t.05    =abs(qt(.05/2,   df=38))
t.03875
t.04
t.04875
power=.9
library(pwr)
install.packages('pwr')
library(pwr)
??pwr
d=pwr.t.test(n=20,power=power)$d
ncp=d*sqrt(10)
ncp
library(devtools)
install_github('rasmusab/bayesian_first_aid')
#R CODE computing share of .04s to .05s with 90% power #Critical t-values for "strong reanalaysis"
t.03875=abs(qt(.03875/2,df=38))
t.04    =abs(qt(.04/2,   df=38))
t.04875=abs(qt(.04875/2,df=38))
t.05    =abs(qt(.05/2,   df=38))
qt(.03875/2,df=38)
abs(qt(.03875/2,df=38))
abs(qt(.04/2,   df=38))
?pwr.t.test
d=pwr.t.test(n=20,power=power)$d
d
sqrt(10)
#R CODE computing share of .04s to .05s with 90% power
#Critical t-values for "strong reanalaysis"
t.03875=abs(qt(.03875/2,df=38))
t.04    =abs(qt(.04/2,   df=38))
t.04875=abs(qt(.04875/2,df=38))
t.05    =abs(qt(.05/2,   df=38))
#Power of true studies
power=.9
#Effect size giving 90% power
library(pwr)
d=pwr.t.test(n=20,power=power)$d
#Noncentrality parameter for desired power
ncp=d*sqrt(10)
#Expected ratio of (.03875-.04) vs (.04875-.05)
#Probability that p<.04
prop1=1-pt(t.04,df=38,ncp=ncp)
#probability that p<.03875
prop2=1-pt(t.03875,df=38,ncp=ncp)
#Probability that p<.05
prop3=1-pt(t.05,df=38,ncp=ncp)
#probability that p<.04875
prop4=1-pt(t.04875,df=38,ncp=ncp)
#Share of p-values in bin .03875-.04
bin.04=prop1-prop2
bin.05=prop3-prop4
#Ratio of .04 to .05
bin.04/bin.05
library(devtools)
install.packages('devtools')
library(devtools)
install_github('stefano-meschiari/latex2exp')
library(latex2exp)
install_github('MicheleNuijten/statcheck')
library(devtools)
install_github('MicheleNuijten/statcheck')
install_github('stefano-meschiari/latex2exp')
library(latex2exp)
plot(1:10, 1:10, xlab = latex2exp('\\alpha\\times\\chi'))
plot(1:10, 1:10, xlab = latex2exp('$\\alpha\\times\\chi$'))
pchisq(q = 147.18, df = 7707)
install.packages('plotly')
library(devtools)
install_github('ropensci/plotly')
install.packages('ggplot2')
install_github('ropensci/plotly')
install.packages('Rcpp')
install.packages("Rcpp")
install_github('ropensci/plotly')
library(devtools)
install_github('ropensci/plotly')
help(signup)
help(signup, package = "plotly")
verify(username)
library(plotly)
verify()
plotly::verify
plotly::verify("chjh")
plotly
?plotly
install.packages('jsonlite')
library(jsonlite)
library(jsonlite)
# url with some information about project in Andalussia
url <- 'http://www.juntadeandalucia.es/export/drupaljda/ayudas.json'
# read url and convert to data.frame
document <- fromJSON(txt=url)
class(document)
document$documentacion
document$documentacion[1]
head(document$documentacion)
head(document$documentacion, 1)
class(document$documentacion)
class(document$documentacion$documentacion_item)
(document$documentacion$documentacion_item)[1]
300-6.18-7.5-1.93-6.46-13.7-26.81-4.99-60
duplicated(readClipboard())
x = readClipboard()
unique(x)
writeClipboard(unique(x))
.5/6
sqrt(.5/6)
if(!require(devtools)){install.packages('devtools')}
if(!require(googlesheets)){install_github('jennybc/googlesheets')}
library(googlesheets)
gs_ls()
install.packages('curl')
install.packages("curl")
gs_ls()
library(googlesheets)
gs_ls()
?gs_url()
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing")
?gs_copy
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read()
library(magrittr)
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read()
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read(range = cell_columns(1:5))
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read(col_names = TRUE)
?gs_read
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read(range = cell_cols(1:5))
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read_csv(range = cell_cols(1:5))
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read_csv()
gs_ls("icanhazpdf")
gs_ls("icanhazpdf") %>% gs_read()
gs_read("icanhazpdf")
gs_read(ss = "icanhazpdf")
gs_title("icanhazpdf") %>% gs_read()
gs_ls()
gs_ls("#icanhaz")
gs_ls("#icanhaz") %>% gs_title()
gs_ls("#icanhazpdf") %>% gs_title("#icanhazpdf")
gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read_csv()
dat <- gs_url("https://docs.google.com/spreadsheets/d/1OXMHv6lal_GiMneW4xHa2wvG4BzTyD41zcCnmfF6PUY/edit?usp=sharing") %>%
gs_read_csv()
dim(dat)
names(dat)
grep("ifttt.com/missing_link", dat$firsturl)
missing.firsturl <- [grep("ifttt.com/missing_link", dat$firsturl)]
missing.firsturl <- grep("ifttt.com/missing_link", dat$firsturl)]
dat$firsturl[missing.firsturl] <- NA
missing.firsturl <- grep("ifttt.com/missing_link", dat$firsturl)
dat$firsturl[missing.firsturl] <- NA
dat$firsturl
setwd("~/Dropbox/projects/2015pppr")
temp <- read.table('datafile_unanon.csv', sep = ';', dec = ',', header = TRUE)
temp$Source
library(ddply)
library(ddplyr)
library(plyr)
length(temp$Raw)
ddply(temp, .(Source), length(Raw))
ddply(temp, .(Source), function(x)
length(x$Raw))
head(ddply(temp, .(Source), function(x)
length(x$Raw)))
head(ddply(temp, .(Source), function(x)
nr.results <- length(x$Raw)
return(nr.results)
)
)
head(ddply(temp, .(Source), function(x)
nr.results <- length(x$Raw)
return(nr.results)))
head(ddply(temp, .(Source), function(x){
nr.results <- length(x$Raw)
return(nr.results)}))
head(ddply(temp, .(Source), function(x){
nr.results <- length(x$Raw)}))
head(ddply(temp, .(Source), summarize, length(Raw)))
head(ddply(temp, .(Source), summarize, nr.results = length(Raw)))
write.table(dat, 'data/nr.results.csv', sep = ';', dec = '.', row.names = FALSE)
dat <- ddply(temp, .(Source), summarize, nr.results = length(Raw))
write.table(dat, 'data/nr.results.csv', sep = ';', dec = '.', row.names = FALSE)
unanon <- read.table('datafile_unanon.csv', sep = ';', dec = ',', header = TRUE)
setwd("~/Dropbox/projects/2015pppr")
unanon <- read.table('data/datafile_unanon.csv', sep = ';', dec = ',', header = TRUE)
head(dat_unanon[sort(dat_unanon$nr.results)])
dat_unanon <- ddply(unanon, .(Source), summarize, nr.results = length(Raw))
head(dat_unanon[sort(dat_unanon$nr.results)])
head(dat_unanon[sort(dat_unanon$nr.results),])
sort(dat_unanon$nr.results)
order(dat_unanon$nr.results)
dat_unanon[order(dat_unanon$nr.results)]
dat_unanon[order(dat_unanon$nr.results),]
# Reading in the unanonymized results
unanon <- read.table('data/datafile_unanon.csv', sep = ';', dec = ',', header = TRUE)
# Getting out the number of results for each unique source
dat_unanon <- ddply(unanon, .(Source), summarize, nr.results = length(Raw))
# Writing out these results in ordered manner to prevent direct linking to anon file
# This way the nr.results does not need to be anonymized
write.table(dat_unanon[order(dat_unanon$nr.results),],
'data/nr.results.unanon.csv', row.names = FALSE,
sep = ';', dec = '.')
setwd("~/Dropbox/projects/2015pppr")
dat <- read.table('data/nr.results.unanon.csv', sep = ';', dec = '.', header = TRUE)
k.sel <- 15
sampleframe <- dat$Source[dat$nr.results >= k.sel]
sample(x = sampleframe, size = n.sel, replace = FALSE)
# Set the threshold for number of results extracted
k.sel = 15
# How many papers to extract?
n.sel = 5
sampleframe <- dat$Source[dat$nr.results >= k.sel]
sample(x = sampleframe, size = n.sel, replace = FALSE)
sampled <- sample(x = sampleframe, size = n.sel, replace = FALSE)
k.sel = 15
# How many papers to extract?
n.sel = 5
# Extract a set of n.sel papers that have >= k.sel results
sampleframe <- dat$Source[dat$nr.results >= k.sel]
set.seed(k.sel + n.sel + 5)
sampled <- sample(x = sampleframe, size = n.sel, replace = FALSE)
# And write out these selected papers into a text file
write.table(sampled, file = 'archive/pilot/sampled_papers.txt', quote = FALSE,
row.names = FALSE, col.names = FALSE)
300-60-14.15-5.48-5.94-3.3-5.61-1.25-5.32-26.81-13.70-6.46-1.93-7.5-6.18-9.05-6.5717.99-11.97-2.6-2.45-23.78-7.37-1.79
300-60-14.15-5.48-5.94-3.3-5.61-1.25-5.32-26.81-13.70-6.46-1.93-7.5-6.18-9.05-6.57-17.99-11.97-2.6-2.45-23.78-7.37-1.79
1.79+7.37+23.78+2.45+2.60+11.97+17.99+6.57+9.05+6.18+7.5+1.93+6.46+13.7+26.81+60+5.32+1.25+5.61+3.3+5.94+5.48+14.15
52.8-100.16
setwd("~/Dropbox/projects/2015pppr")
if(!require(statcheck)){install.packages('statcheck')}
library(statcheck)
checkHTMLdir(dir = 'archive/pilot')
write.table(x, 'archive/pilot/pilot_statcheck.csv', sep = ';', dec = '.', row.names = FALSE)
x <- checkHTMLdir(dir = 'archive/pilot')
write.table(x, 'archive/pilot/pilot_statcheck.csv', sep = ';', dec = '.', row.names = FALSE)
x = readClipboard()
substr(x, start = 8, 11)
substr(x, start = 8, 10)
writeClipboard(substr(x, start = 8, 10))
x = readClipboard()
x
x = readClipboard()
substr(x, start = -5, stop = 10000)
substr(x, start = -5L, stop = 10000)
regexpr("\\.[^\\\]*$", x)
regexpr("\\.[^\\/]*$", x)
?regex
regexpr('.*(?!/*$)', x)
regexpr('.*[?!/*$]', x)
y = regexpr('.*[?!/*$]', x)
y
y[[2]]
class(y)
y[1]
y[240
]
regexpr('[?!/*$]', x)
grep('[?!/*$]', x)
regex('[?!/*$]', x)
regexpr('[?!/*$]', x)
regexpr('*[?!/*$]', x)
regexpr('.*[?!/*$]', x)
y = regexpr('.*[?!/*$]', x)
class(y)
writeClipboard(y)
y = regexpr('.*[?!/*$]', x)
substr(x, start = y, stop = 10000L)
y = gregexpr('.*[?!/*$]', x)
y
substr(x, start = y, stop = 10000L)
y
y[[1]]
y[[1]][2]
class(y[[1]])
?gregexpr
which(strsplit(x, "")[[1]]=="/")
strsplit(x, "")
x
strsplit(x, "")
library(stringr)
str_locate_all(x, '/')
x
substr(x, nchar(x) - 5, 10000L)
substr(x, nchar(x) - 4, 10000L)
writeClipboard(x)
